# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
commands:
  print_pipeline_id:
    description: "A very simple command for demonstration purposes"
    parameters:
      to:
        type: string
        default: "Hello Command"
    steps:
      - run: echo << parameters.to >>

  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name infraStack-${CIRCLE_WORKFLOW_ID:0:5}

jobs:

  # create_infrastructure: 
  #   docker:
  #     - image: amazon/aws-cli
  #   steps:
  #     - checkout
  #     - run:
  #         name: Create Cloudformation Stack
  #         command: |
  #           aws cloudformation deploy \
  #             --template-file template.yml \
  #             --stack-name infraStack-${CIRCLE_WORKFLOW_ID:0:5} \
  #             --region us-east-1

  configure_infrastructure: 
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - run: apk add --update openssh-client git
      - add_ssh_keys:
          fingerprints: ["09:1e:fe:a5:04:c4:d4:af:0c:cc:97:a2:cd:bf:c6:6f"] # ID in the section where you registered the SSH Key
      - run:
          name: Install dependencies
          command: |
            # install the dependencies needed for your playbook
            apk add --update ansible 
      - run:
          name: Configure server
          command: |
            ansible-playbook -i inventory.txt main-remote.yml

  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - run: apk add --update curl
      - run:
          name: smoke test
          command: |
            URL="https://blog.udacity.com/"
            # Test if website exists
            if curl -s --head ${URL} 
            then
              return 0
            else
              return 1
            fi


  smoke_infra_test:
    docker:
      - image: amazon/aws-cli
    steps:
      - run:
          name: Test job
          # Fail the job intentionally to simulate an error.
          command:  return 1
      - destroy_environment

# Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:6} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:6}"
      # Uncomment the step below if you wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:6} --delete

  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:6}"             

  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous production version's S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://mybucket910001440437" --recursive

  new-job:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - print_pipeline_id:
          to: $CIRCLE_WORKFLOW_ID

  # exit-on-purpose:
  #   docker:
  #     - image: cimg/base:stable
  #   steps:
  #     - run: exit 1
  #     - run:
  #         name: on error
  #         command: echo "Hello Error!"
  #         when: on_fail

  print-name:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - run:
          name: "Print Name"
          command: echo $NAME

  save_hello_world_output:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - run:
          name: "Save text Output to file"
          command: echo "text to output here" > output.txt
      - persist_to_workspace:
          root: .
          paths: 
            - output.txt

  print_output_file:
    docker:
      - image: cimg/base:stable
    steps:
      # attach the files you persisted in the doing-things-job
      - attach_workspace:
          at: . # relative path to our working directory
      - run:
          command: |
            cat output.txt
    
      

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  version: 2
  say-hello-workflow:

    jobs:
      # - create_infrastructure
      - configure_infrastructure
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
      - smoke_test
      - smoke_infra_test
      # - exit-on-purpose
      # - new-job    
      # - save_hello_world_output
      # - print_output_file:
      #     requires:
      #       - save_hello_world_output
      - print-name
